{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51047, 58)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"./data/raw/cell2celltrain.csv\")\n",
    "print (df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Column Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "def camel_to_snake(name):\n",
    "    s1 = re.sub('(.)([A-Z][a-z]+)', r'\\1_\\2', name)\n",
    "    snake_case = re.sub('([a-z0-9])([A-Z])', r'\\1_\\2', s1).lower()\n",
    "    return snake_case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = [camel_to_snake(col) for col in df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('not_new_cellphone_user', axis=1)\n",
    "df = df.drop('service_area', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "## New Features\n",
    "# TotalCareIssues=CustomerCareCalls+BlockedCalls+DroppedBlockedCalls\n",
    "df['total_care_issues'] = df['customer_care_calls'] + df['blocked_calls'] + df['dropped_blocked_calls']\n",
    "df = df.drop(['customer_care_calls', 'blocked_calls', 'dropped_blocked_calls'], axis=1)\n",
    "\n",
    "# OverallRevenue=MonthlyRevenue+TotalRecurringCharge\n",
    "df['overall_revenue'] = df['monthly_revenue'] + df['total_recurring_charge']\n",
    "df = df.drop(['monthly_revenue', 'total_recurring_charge'], axis=1)\n",
    "\n",
    "# OverallUsage=MonthlyMinutes + OverageMinutes + RoamingCalls\n",
    "df['overall_usage'] = df['monthly_minutes'] + df['overage_minutes'] + df['roaming_calls']\n",
    "df = df.drop(['monthly_minutes', 'overage_minutes', 'roaming_calls'], axis=1)\n",
    "\n",
    "# ValueAddedServiceUsage=DirectorAssistedCalls + ThreewayCalls + CallForwardingCalls + CallWaitingCalls\n",
    "df['value_added_service_usage'] = df['director_assisted_calls'] + df['threeway_calls'] + df['call_forwarding_calls'] + df['call_waiting_calls']\n",
    "df = df.drop(['director_assisted_calls', 'threeway_calls', 'call_forwarding_calls', 'call_waiting_calls'], axis=1)\n",
    "\n",
    "#TotalCalls=InboundCalls+OutboundCalls\n",
    "df['total_calls'] = df['inbound_calls'] + df['outbound_calls']\n",
    "df = df.drop(['inbound_calls', 'outbound_calls'], axis=1)\n",
    "\n",
    "#TotalPeakoffPeakcall =PeakCallsInOut+OffPeakCallsInOut\n",
    "df['total_peak_off_peak_calls'] = df['peak_calls_in_out'] + df['off_peak_calls_in_out']\n",
    "df = df.drop(['peak_calls_in_out', 'off_peak_calls_in_out'], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Data Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_categories(df, verbose=False):\n",
    "    quantitative_columns = df.select_dtypes(include=['float64']).columns\n",
    "    quantitative_discrete_columns = df.select_dtypes(include=['int64']).columns\n",
    "    id_columns = ['customer_id']\n",
    "    quantitative_discrete_columns = [col for col in quantitative_discrete_columns if col not in id_columns]\n",
    "    categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "    binary_columns = [col for col in categorical_columns if df[col].nunique() == 2]\n",
    "    categorical_columns = [col for col in categorical_columns if col not in binary_columns]\n",
    "\n",
    "    if verbose:\n",
    "        print(\"\\nQuantitative Variables:\", list(quantitative_columns))\n",
    "        print(\"Total Quantitative-Continuous Variables:\", len(quantitative_columns))\n",
    "\n",
    "        print(\"\\nQuantitative Discrete Variables:\", list(quantitative_discrete_columns))\n",
    "        print(\"Total Quantitative-Discrete Variables:\", len(quantitative_discrete_columns))\n",
    "\n",
    "        print(\"\\nCategorical Variables:\", list(categorical_columns))\n",
    "        print(\"Total Categorical Variables:\", len(categorical_columns))\n",
    "\n",
    "        print(\"\\nBinary Variables:\", list(binary_columns))\n",
    "        print(\"Total Binary Variables:\", len(binary_columns))\n",
    "\n",
    "    return quantitative_columns, quantitative_discrete_columns, categorical_columns, binary_columns, id_columns\n",
    "\n",
    "quantitative_columns, quantitative_discrete_columns, categorical_columns, binary_columns, id_columns = get_data_categories(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Variable Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in binary_columns:\n",
    "    if col == \"homeownership\":\n",
    "        df[col] = df[col].map({\"Known\": 1, \"Unknown\": 0})\n",
    "    else:\n",
    "        df[col] = df[col].map({\"Yes\": 1, \"No\": 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantitative Variables Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_regression_imputer(df, column):\n",
    "\n",
    "    df_known = df[df[column].notna()]\n",
    "    df_missing = df[df[column].isna()]\n",
    "\n",
    "    # Select features for the model\n",
    "    features = df.columns.difference([column])\n",
    "\n",
    "    # Define training data and replace NaNs with 0\n",
    "    X_known = df_known[features].fillna(0)\n",
    "    y_known = df_known[column].fillna(0)\n",
    "\n",
    "    # Train a Linear Regression model\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_known, y_known)\n",
    "\n",
    "    # Predict missing values for this column\n",
    "    X_missing = df_missing[features].fillna(0)  # Replace NaNs with 0 in missing data\n",
    "\n",
    "    predicted_values = model.predict(X_missing)\n",
    "    random_noise = np.random.normal(\n",
    "        loc=0, scale=y_known.std(), size=predicted_values.shape\n",
    "    )\n",
    "    # only positive values\n",
    "    df.loc[df[column].isna(), column] = np.max(predicted_values + random_noise, 0)\n",
    "    return df[column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_df = df[quantitative_columns].copy()\n",
    "for col in quant_df.columns:\n",
    "    if df[col].isna().sum() > 0:\n",
    "        df[col] = random_regression_imputer(quant_df, col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trim Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_outliers_iqr_multiple_columns(df: pd.DataFrame, columns:str, threshold: float) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Trim outliers from multiple DataFrame columns using the IQR method.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The DataFrame to process.\n",
    "        columns (list): A list of column names from which to trim outliers.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with outliers removed.\n",
    "    \"\"\"\n",
    "    for column in columns:\n",
    "        print(f\"Processing column: {column}\")\n",
    "        Q1 = df[column].quantile(0.25)\n",
    "        Q3 = df[column].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - threshold * IQR\n",
    "        upper_bound = Q3 + threshold * IQR\n",
    "        \n",
    "        print(\"Dimensions before:\", df.shape)\n",
    "        # Create a mask for values within bounds\n",
    "        mask = (df[column] >= lower_bound) & (df[column] <= upper_bound)\n",
    "        \n",
    "        # Apply the mask to keep only the non-outliers\n",
    "        df = df[mask]\n",
    "        print(\"Dimensions after:\", df.shape)\n",
    "        \n",
    "    return df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing column: perc_change_minutes\n",
      "Dimensions before: (33243, 46)\n",
      "Dimensions after: (32535, 46)\n",
      "Processing column: perc_change_revenues\n",
      "Dimensions before: (32535, 46)\n",
      "Dimensions after: (28309, 46)\n",
      "Processing column: dropped_calls\n",
      "Dimensions before: (28309, 46)\n",
      "Dimensions after: (27841, 46)\n",
      "Processing column: unanswered_calls\n",
      "Dimensions before: (27841, 46)\n",
      "Dimensions after: (27517, 46)\n",
      "Processing column: received_calls\n",
      "Dimensions before: (27517, 46)\n",
      "Dimensions after: (27051, 46)\n",
      "Processing column: handsets\n",
      "Dimensions before: (27051, 46)\n",
      "Dimensions after: (27051, 46)\n",
      "Processing column: handset_models\n",
      "Dimensions before: (27051, 46)\n",
      "Dimensions after: (27051, 46)\n",
      "Processing column: current_equipment_days\n",
      "Dimensions before: (27051, 46)\n",
      "Dimensions after: (27051, 46)\n",
      "Processing column: age_hh1\n",
      "Dimensions before: (27051, 46)\n",
      "Dimensions after: (27051, 46)\n",
      "Processing column: age_hh2\n",
      "Dimensions before: (27051, 46)\n",
      "Dimensions after: (27051, 46)\n",
      "Processing column: total_care_issues\n",
      "Dimensions before: (27051, 46)\n",
      "Dimensions after: (26659, 46)\n",
      "Processing column: overall_revenue\n",
      "Dimensions before: (26659, 46)\n",
      "Dimensions after: (26620, 46)\n",
      "Processing column: overall_usage\n",
      "Dimensions before: (26620, 46)\n",
      "Dimensions after: (26530, 46)\n",
      "Processing column: value_added_service_usage\n",
      "Dimensions before: (26530, 46)\n",
      "Dimensions after: (26009, 46)\n",
      "Processing column: total_calls\n",
      "Dimensions before: (26009, 46)\n",
      "Dimensions after: (25678, 46)\n",
      "Processing column: total_peak_off_peak_calls\n",
      "Dimensions before: (25678, 46)\n",
      "Dimensions after: (25651, 46)\n"
     ]
    }
   ],
   "source": [
    "df = trim_outliers_iqr_multiple_columns(\n",
    "    df, \n",
    "    quantitative_columns,\n",
    "    threshold=3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "handset_price     0\n",
       "credit_rating     0\n",
       "prizm_code        0\n",
       "occupation        0\n",
       "marital_status    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# handset_price\n",
    "# credit_rating\n",
    "\n",
    "df['handset_price'] = df['handset_price'].replace(\"Unknown\", np.nan).astype(float)\n",
    "df['handset_price'] = df['handset_price'].fillna(df['handset_price'].mean())\n",
    "\n",
    "df['credit_rating'] = df['credit_rating'].str.split('-').str[0].str.strip()\n",
    "df['credit_rating'] = df['credit_rating'].astype(int)\n",
    "\n",
    "\n",
    "df[categorical_columns].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_vars = [\n",
    "    \"prizm_code\",\n",
    "    \"occupation\",\n",
    "    \"marital_status\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore')\n",
    "encoder.fit(df[ohe_vars])\n",
    "\n",
    "train_encoded = encoder.transform(df[ohe_vars])\n",
    "train_encoded_df = pd.DataFrame(train_encoded, columns=encoder.get_feature_names_out())\n",
    "\n",
    "df = pd.concat([df.drop(ohe_vars, axis=1), train_encoded_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero Inflated Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['retention_calls',\n",
       " 'retention_offers_accepted',\n",
       " 'referrals_made_by_subscriber',\n",
       " 'income_group',\n",
       " 'adjustments_to_credit_rating',\n",
       " 'perc_change_revenues',\n",
       " 'dropped_calls',\n",
       " 'unanswered_calls',\n",
       " 'received_calls',\n",
       " 'age_hh1',\n",
       " 'age_hh2',\n",
       " 'total_care_issues',\n",
       " 'value_added_service_usage',\n",
       " 'total_calls',\n",
       " 'total_peak_off_peak_calls']"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get zero inflated features\n",
    "def get_zero_inflated_features(df, threshold=0.5):\n",
    "    zero_inflated = []\n",
    "    for col in df.columns:\n",
    "        if df[col].value_counts().get(0) is None:\n",
    "            continue\n",
    "\n",
    "        if df[col].value_counts().get(0) / len(df) > threshold:\n",
    "            zero_inflated.append(col)\n",
    "    return zero_inflated\n",
    "\n",
    "\n",
    "nonbinary_feature_names = list(quantitative_discrete_columns) + list(quantitative_columns)\n",
    "\n",
    "zero_inflated_features = get_zero_inflated_features(df[nonbinary_feature_names], threshold=0.1)\n",
    "zero_inflated_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make indicator for zero inflated features\n",
    "for feature in zero_inflated_features:\n",
    "    df[f'{feature}_is_zero'] = (df[feature] == 0).astype(int)\n",
    "    df[f'{feature}_is_zero'] = (df[feature] == 0).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Train Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, train_size = 0.80, random_state = random_state)\n",
    "\n",
    "X_train = train.drop('churn', axis=1).reset_index(drop=True)\n",
    "y_train = train['churn'].reset_index(drop=True)\n",
    "\n",
    "X_test = test.drop('churn', axis=1).reset_index(drop=True)\n",
    "y_test = test['churn'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv(\"./data/prod/X_train.csv\", index=False)\n",
    "y_train.to_csv(\"./data/prod/y_train.csv\", index=False)\n",
    "\n",
    "X_test.to_csv(\"./data/prod/X_test.csv\", index=False)\n",
    "y_test.to_csv(\"./data/prod/y_test.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
